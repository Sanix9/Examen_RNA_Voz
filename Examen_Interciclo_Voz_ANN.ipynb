{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "      <th>611</th>\n",
       "      <th>612</th>\n",
       "      <th>613</th>\n",
       "      <th>614</th>\n",
       "      <th>615</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.4394</td>\n",
       "      <td>-0.0930</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.4704</td>\n",
       "      <td>0.3578</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>-0.1184</td>\n",
       "      <td>-0.2310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>0.2052</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.5898</td>\n",
       "      <td>-0.4872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4348</td>\n",
       "      <td>-0.1198</td>\n",
       "      <td>0.2474</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>-0.0520</td>\n",
       "      <td>-0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4772</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.2046</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.4546</td>\n",
       "      <td>-0.0910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2330</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.5014</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>-0.3422</td>\n",
       "      <td>-0.5840</td>\n",
       "      <td>-0.7168</td>\n",
       "      <td>-0.6342</td>\n",
       "      <td>-0.8614</td>\n",
       "      <td>-0.8318</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1112</td>\n",
       "      <td>-0.0476</td>\n",
       "      <td>-0.1746</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>-0.0476</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.1588</td>\n",
       "      <td>-0.4762</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.3808</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.2602</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>-0.4290</td>\n",
       "      <td>-0.6746</td>\n",
       "      <td>-0.6868</td>\n",
       "      <td>-0.6650</td>\n",
       "      <td>-0.8410</td>\n",
       "      <td>-0.9614</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0504</td>\n",
       "      <td>-0.0360</td>\n",
       "      <td>-0.1224</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>-0.1510</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.3412</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>-0.1622</td>\n",
       "      <td>-0.3784</td>\n",
       "      <td>-0.4324</td>\n",
       "      <td>-0.4358</td>\n",
       "      <td>-0.4966</td>\n",
       "      <td>-0.5406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>-0.0938</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.3124</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1       2       3       4       5       6       7       8    \\\n",
       "0 -0.4394 -0.0930  0.1718  0.4620  0.6226  0.4704  0.3578  0.0478 -0.1184   \n",
       "1 -0.4348 -0.1198  0.2474  0.4036  0.5026  0.6328  0.4948  0.0338 -0.0520   \n",
       "2 -0.2330  0.2124  0.5014  0.5222 -0.3422 -0.5840 -0.7168 -0.6342 -0.8614   \n",
       "3 -0.3808 -0.0096  0.2602  0.2554 -0.4290 -0.6746 -0.6868 -0.6650 -0.8410   \n",
       "4 -0.3412  0.0946  0.6082  0.6216 -0.1622 -0.3784 -0.4324 -0.4358 -0.4966   \n",
       "\n",
       "      9    ...     608     609     610     611     612     613     614  \\\n",
       "0 -0.2310  ...  0.4102  0.2052  0.3846  0.3590  0.5898  0.3334  0.6410   \n",
       "1 -0.1302  ...  0.0000  0.2954  0.2046  0.4772  0.0454  0.2046  0.4318   \n",
       "2 -0.8318  ... -0.1112 -0.0476 -0.1746  0.0318 -0.0476  0.1112  0.2540   \n",
       "3 -0.9614  ... -0.0504 -0.0360 -0.1224  0.1366  0.2950  0.0792 -0.0072   \n",
       "4 -0.5406  ...  0.1562  0.3124  0.2500 -0.0938  0.1562  0.3124  0.3124   \n",
       "\n",
       "      615     616  617  \n",
       "0  0.5898 -0.4872  1.0  \n",
       "1  0.4546 -0.0910  1.0  \n",
       "2  0.1588 -0.4762  2.0  \n",
       "3  0.0936 -0.1510  2.0  \n",
       "4  0.2188 -0.2500  3.0  \n",
       "\n",
       "[5 rows x 618 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "datos = pd.read_csv('corpus/voz/pronunciacion.data', header=None)\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>-0.394077</td>\n",
       "      <td>0.240579</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-0.55520</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.24845</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.141918</td>\n",
       "      <td>0.322356</td>\n",
       "      <td>-0.8926</td>\n",
       "      <td>-0.10080</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.35555</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.343198</td>\n",
       "      <td>0.325086</td>\n",
       "      <td>-0.9752</td>\n",
       "      <td>0.09905</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.57875</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.445395</td>\n",
       "      <td>0.308172</td>\n",
       "      <td>-0.9680</td>\n",
       "      <td>0.24720</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.66195</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.321922</td>\n",
       "      <td>0.465508</td>\n",
       "      <td>-0.9966</td>\n",
       "      <td>-0.03790</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>0.69560</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.220475</td>\n",
       "      <td>0.339323</td>\n",
       "      <td>-0.8106</td>\n",
       "      <td>-0.02560</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.45800</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.180992</td>\n",
       "      <td>0.341432</td>\n",
       "      <td>-0.7802</td>\n",
       "      <td>-0.06660</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.40720</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.082916</td>\n",
       "      <td>0.336243</td>\n",
       "      <td>-0.8028</td>\n",
       "      <td>-0.15670</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.29610</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>-0.272561</td>\n",
       "      <td>0.357741</td>\n",
       "      <td>-0.9626</td>\n",
       "      <td>-0.54135</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>-0.05400</td>\n",
       "      <td>0.8898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>6238.0</td>\n",
       "      <td>13.502405</td>\n",
       "      <td>7.500601</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       mean       std     min      25%      50%       75%      max\n",
       "0    6238.0  -0.394077  0.240579 -1.0000 -0.55520  -0.4230  -0.24845   1.0000\n",
       "1    6238.0   0.141918  0.322356 -0.8926 -0.10080   0.1066   0.35555   1.0000\n",
       "2    6238.0   0.343198  0.325086 -0.9752  0.09905   0.3300   0.57875   1.0000\n",
       "3    6238.0   0.445395  0.308172 -0.9680  0.24720   0.4490   0.66195   1.0000\n",
       "4    6238.0   0.321922  0.465508 -0.9966 -0.03790   0.4190   0.69560   1.0000\n",
       "..      ...        ...       ...     ...      ...      ...       ...      ...\n",
       "613  6238.0   0.220475  0.339323 -0.8106 -0.02560   0.1866   0.45800   1.0000\n",
       "614  6238.0   0.180992  0.341432 -0.7802 -0.06660   0.1478   0.40720   1.0000\n",
       "615  6238.0   0.082916  0.336243 -0.8028 -0.15670   0.0468   0.29610   1.0000\n",
       "616  6238.0  -0.272561  0.357741 -0.9626 -0.54135  -0.3182  -0.05400   0.8898\n",
       "617  6238.0  13.502405  7.500601  1.0000  7.00000  14.0000  20.00000  26.0000\n",
       "\n",
       "[618 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49976896,  0.71070705,  0.11783495, ...,  1.84120087,\n",
       "         2.21329379,  2.24447811],\n",
       "       [-0.22650961, -0.37145917, -0.44521256, ...,  2.40737368,\n",
       "         2.54116307,  1.61851698],\n",
       "       [ 0.32863435,  0.25241431, -0.10009901, ..., -0.0298599 ,\n",
       "         0.11422403, -0.10010145],\n",
       "       [-0.68815565, -0.40556756, -1.21940288, ...,  2.40737368,\n",
       "         1.55108025,  1.78277629],\n",
       "       [ 0.28105058, -0.5854118 ,  0.19685916, ..., -0.17783688,\n",
       "        -0.70515485, -0.16613813],\n",
       "       [ 1.59503043,  1.06481416,  1.02537862, ..., -1.56168488,\n",
       "        -1.12956015, -0.5290624 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from viznet import connecta2a, node_sequence, NodeBrush, EdgeBrush, DynamicShow\n",
    "# Importamos la funciÃ³n para escalar los valores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Importamos la funciÃ³n para separar test y train\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importamos la funciÃ³n para escalar los valores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "\n",
    "# Creamos variables con los parametros que tendra la red\n",
    "entradas = 617\n",
    "neuronas_capa_oculta = 7\n",
    "neuronas_capa_salida = 26\n",
    "\n",
    "# Separamos en una variable los datos de entrada, para ello generamos una copia del dataframe\n",
    "# eliminando la Ãºltima columna del corpus (la que tiene los tipos de flores)\n",
    "X=datos.drop(datos.columns[[617]], axis='columns')\n",
    "\n",
    "# Procedemos de la misma forma, pero en este caso para generar un arreglo que tenga las salidas\n",
    "# deseadas\n",
    "d=datos[617]\n",
    "\n",
    "# Mostramos en pantalla los primeros datos con la funciÃ³n 'head'\n",
    "#print('Datos de Entrada\\n')\n",
    "X.head()\n",
    "#print('\\nDatos de Salida\\n')\n",
    "d.head()\n",
    "\n",
    "X_train, X_test, d_train, d_test = train_test_split(X,d,train_size=0.70,random_state=0,stratify=d)\n",
    "\n",
    "#Realizamos OneHotEncoding para contar con 26 salidas en vez de 1 y luego realizar un dataframe con pandas\n",
    "dat_dict=datos.T.to_dict().values()\n",
    "vectorizer = DV(sparse = False)\n",
    "vectorizer.fit(dat_dict)\n",
    "dat= vectorizer.transform(dat_dict)\n",
    "dat=pd.DataFrame(dat)\n",
    "\n",
    "# Generamos un objeto para escalar los valores\n",
    "scaler=StandardScaler()\n",
    "\n",
    "# Ajuste solo en los datos de entrenamiento\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Escalamos el corpus de entrenamiento\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "# Visualizamos las 7 primeras filas de datos\n",
    "X_train[1:7,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(7, 26), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=None, shuffle=True, solver='lbfgs', tol=1e-15,\n",
      "              validation_fraction=0.1, verbose=True, warm_start=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(7, 26), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='lbfgs', tol=1e-15,\n",
       "              validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos el Perceptron Multicapa para Clasificacion\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Creamos la red neuronal\n",
    "mlp=MLPClassifier(solver = 'lbfgs', activation='logistic', verbose=True, alpha=1e-4, tol=1e-15, max_iter=10000, \\\n",
    "                  hidden_layer_sizes=(neuronas_capa_oculta, neuronas_capa_salida))\n",
    "\n",
    "print(mlp)\n",
    "# Realizamos el proceso de entrenamiento\n",
    "mlp.fit(X_train,d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.0    72\n",
      "6.0     72\n",
      "2.0     72\n",
      "9.0     72\n",
      "7.0     72\n",
      "5.0     72\n",
      "16.0    72\n",
      "10.0    72\n",
      "24.0    72\n",
      "12.0    72\n",
      "21.0    72\n",
      "3.0     72\n",
      "11.0    72\n",
      "20.0    72\n",
      "18.0    72\n",
      "1.0     72\n",
      "13.0    72\n",
      "14.0    72\n",
      "4.0     72\n",
      "26.0    72\n",
      "25.0    72\n",
      "8.0     72\n",
      "19.0    72\n",
      "22.0    72\n",
      "17.0    72\n",
      "15.0    72\n",
      "Name: 617, dtype: int64\n",
      "Matriz de Confusion\n",
      "\n",
      "[[57  1  0  0  1  0  0  6  0  0  3  0  0  0  0  0  0  0  0  0  0  2  1  0\n",
      "   1  0]\n",
      " [ 0 53  0  7  2  0  0  1  0  0  0  0  0  0  1  1  0  0  0  0  0  5  1  0\n",
      "   0  1]\n",
      " [ 0  0 63  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0\n",
      "   0  6]\n",
      " [ 0 13  0 46  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  2  0  0\n",
      "   0  0]\n",
      " [ 0 11  0  4 52  0  0  0  1  0  0  0  0  0  0  2  0  0  0  0  0  2  0  0\n",
      "   0  0]\n",
      " [ 1  0  1  0  0 51  0  0  0  0  0  0  0  3  0  0  0  0 12  0  0  0  4  0\n",
      "   0  0]\n",
      " [ 0  0  1  1  0  0 47  0  0  1  0  0  0  0  0  1  6  0  0 10  0  3  0  0\n",
      "   0  2]\n",
      " [ 4  5  0  0  0  0  0 62  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "   0  0]\n",
      " [ 0  3  0  0  0  0  0  0 66  0  0  0  0  0  0  0  0  2  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0 54  7  0  0  2  0  0  7  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 3  0  1  0  0  0  0  0  0  4 62  0  0  0  0  1  1  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 60  2  0  6  0  0  0  0  0  1  0  0  3\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1 59  7  1  0  1  0  0  0  1  0  1  0\n",
      "   1  0]\n",
      " [ 6  0  0  0  0  1  1  0  4  1  0  2 12 41  0  0  0  0  0  0  0  0  1  1\n",
      "   2  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  4  0  0 62  0  0  4  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  5  2  0  3  0  1  0  0  0  4  0  0  0  0 44  0  0  0  7  0  2  2  0\n",
      "   0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  8  0  1  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  0  0  0  2  0  0  0  0  0 11  0  0 58  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0  0 67  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  1  0  0 18  0  0  0  0  0  0  0  0  5  0  0  0 46  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 72  0  0  0\n",
      "   0  0]\n",
      " [ 0  7  0 11  1  0  4  0  0  0  0  0  0  0  0  0  0  0  1  2  0 43  3  0\n",
      "   0  0]\n",
      " [ 0  2  2  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0  0  0  0  0 64  0\n",
      "   1  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  3  0  0  0  0 66\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  3  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "  66  0]\n",
      " [ 0  0  5  0  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  1  0  8  1  0\n",
      "   0 53]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.79      0.78        72\n",
      "         2.0       0.52      0.74      0.61        72\n",
      "         3.0       0.82      0.88      0.85        72\n",
      "         4.0       0.66      0.64      0.65        72\n",
      "         5.0       0.78      0.72      0.75        72\n",
      "         6.0       0.89      0.71      0.79        72\n",
      "         7.0       0.61      0.65      0.63        72\n",
      "         8.0       0.90      0.86      0.88        72\n",
      "         9.0       0.85      0.92      0.88        72\n",
      "        10.0       0.90      0.75      0.82        72\n",
      "        11.0       0.82      0.86      0.84        72\n",
      "        12.0       0.90      0.83      0.86        72\n",
      "        13.0       0.81      0.82      0.81        72\n",
      "        14.0       0.77      0.57      0.66        72\n",
      "        15.0       0.74      0.86      0.79        72\n",
      "        16.0       0.80      0.61      0.69        72\n",
      "        17.0       0.79      0.88      0.83        72\n",
      "        18.0       0.91      0.81      0.85        72\n",
      "        19.0       0.81      0.93      0.86        72\n",
      "        20.0       0.65      0.64      0.64        72\n",
      "        21.0       0.88      1.00      0.94        72\n",
      "        22.0       0.63      0.60      0.61        72\n",
      "        23.0       0.79      0.89      0.84        72\n",
      "        24.0       0.94      0.92      0.93        72\n",
      "        25.0       0.93      0.92      0.92        72\n",
      "        26.0       0.84      0.74      0.79        72\n",
      "\n",
      "    accuracy                           0.79      1872\n",
      "   macro avg       0.80      0.79      0.79      1872\n",
      "weighted avg       0.80      0.79      0.79      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(d_test.value_counts())\n",
    "\n",
    "prediccion = mlp.predict(X_test)\n",
    "print('Matriz de Confusion\\n')\n",
    "print(confusion_matrix(d_test, prediccion))\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(d_test, prediccion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
