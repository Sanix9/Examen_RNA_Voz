{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold, ShuffleSplit,train_test_split, PredefinedSplit\n",
    "from sklearn.ensemble import RandomForestRegressor , ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "def gini(solution, submission):\n",
    "    df = zip(solution, submission, range(len(solution)))\n",
    "    df = sorted(df, key=lambda x: (x[1],-x[2]), reverse=True)\n",
    "    rand = [float(i+1)/float(len(df)) for i in range(len(df))]\n",
    "    totalPos = float(sum([x[0] for x in df]))\n",
    "    cumPosFound = [df[0][0]]\n",
    "    for i in range(1,len(df)):\n",
    "        cumPosFound.append(cumPosFound[len(cumPosFound)-1] + df[i][0])\n",
    "    Lorentz = [float(x)/totalPos for x in cumPosFound]\n",
    "    Gini = [Lorentz[i]-rand[i] for i in range(len(df))]\n",
    "    return sum(Gini)\n",
    "\n",
    "def normalized_gini(solution, submission):\n",
    "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n",
    "    return normalized_gini\n",
    "\n",
    "# Normalized Gini Scorer\n",
    "gini_scorer = metrics.make_scorer(normalized_gini, greater_is_better = True)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    dat=pd.datos = pd.read_csv('corpus/voz/pronunciacion.data', header=None)\n",
    "    y=dat[617]\n",
    "    dat=X=dat.drop(dat.columns[[617]], axis='columns')\n",
    "\n",
    "\n",
    "    folds=train_test_split(range(len(y)),test_size=0.30, random_state=15) #30% test\n",
    "\n",
    "    #First one hot and make a pandas df\n",
    "    dat_dict=dat.T.to_dict().values()\n",
    "    vectorizer = DV( sparse = False )\n",
    "    vectorizer.fit( dat_dict )\n",
    "    dat= vectorizer.transform( dat_dict )\n",
    "    dat=pd.DataFrame(dat)\n",
    "\n",
    "\n",
    "    train_X=dat.iloc[folds[0],:]\n",
    "    train_y=y[folds[0]]\n",
    "    test_X=dat.iloc[folds[1],:]\n",
    "    test_y=y[folds[1]]\n",
    "\n",
    "\n",
    "    rf=RandomForestRegressor(n_estimators=1000, n_jobs=1, random_state=15)\n",
    "    rf.fit(train_X,train_y)\n",
    "    y_submission=rf.predict(test_X)\n",
    "    print(\"Validation Sample Score: {:.10f} (normalized gini).\".format(normalized_gini(test_y,y_submission)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
